{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-21T17:26:38.579488Z",
     "start_time": "2025-03-21T17:26:27.114591Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T17:26:39.423384Z",
     "start_time": "2025-03-21T17:26:38.599536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('Ad_table (extra).csv')\n",
    "print(f\"Всего записей: {len(df)}\")\n",
    "print(df['Color'].value_counts())"
   ],
   "id": "a1e9569c7b951ed3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего записей: 268255\n",
      "Color\n",
      "Black          48751\n",
      "Silver         40214\n",
      "Blue           38376\n",
      "Grey           37678\n",
      "White          34270\n",
      "Red            25987\n",
      "Green           5027\n",
      "Yellow          3072\n",
      "Brown           2878\n",
      "Orange          2829\n",
      "Beige           1982\n",
      "Purple          1361\n",
      "Gold            1223\n",
      "Bronze          1200\n",
      "Multicolour      800\n",
      "Pink             299\n",
      "Maroon           179\n",
      "Turquoise        176\n",
      "Burgundy          48\n",
      "Magenta           18\n",
      "Navy               8\n",
      "Indigo             4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T17:26:42.814661Z",
     "start_time": "2025-03-21T17:26:39.684783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explore_image_directory(root_dir):\n",
    "    car_images = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                car_images.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f\"Найдено {len(car_images)} изображений\")\n",
    "    return car_images\n",
    "\n",
    "car_images = explore_image_directory('confirmed_fronts')\n",
    "print(f\"Пример пути к изображению: {car_images[0]}\")"
   ],
   "id": "21ae3eac3e6f7f9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 61827 изображений\n",
      "Пример пути к изображению: confirmed_fronts\\Abarth\\2013\\Abarth$$595$$2013$$Black$$2_4$$100$$image_1.jpg\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T17:26:43.489019Z",
     "start_time": "2025-03-21T17:26:42.927251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_color_from_filename(filename):\n",
    "    # Abarth $$ 595 $$ 2013 $$ Black $$ 2_4 $$ 100 $$ image_1.jpg\n",
    "    parts = os.path.basename(filename).split('$$')\n",
    "    if len(parts) >= 4:\n",
    "        return parts[3]\n",
    "    return None\n",
    "\n",
    "image_colors = {}\n",
    "for img_path in car_images:\n",
    "    color = extract_color_from_filename(img_path)\n",
    "    if color:\n",
    "        image_colors[img_path] = color\n",
    "\n",
    "print(f\"Найдено {len(image_colors)} изображений с цветами\")\n",
    "color_distribution = pd.Series(list(image_colors.values())).value_counts()\n",
    "print(color_distribution)"
   ],
   "id": "b45c34561a3bcc7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 61827 изображений с цветами\n",
      "Black          14317\n",
      "Grey            9474\n",
      "White           9395\n",
      "Blue            8483\n",
      "Silver          7770\n",
      "Red             6095\n",
      "Unlisted        1516\n",
      "Brown            911\n",
      "Green            777\n",
      "Yellow           667\n",
      "Beige            600\n",
      "Orange           559\n",
      "Purple           362\n",
      "Bronze           329\n",
      "Gold             217\n",
      "Multicolour      196\n",
      "Pink              87\n",
      "Turquoise         26\n",
      "Maroon            26\n",
      "Burgundy           9\n",
      "Magenta            9\n",
      "Navy               1\n",
      "Indigo             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T17:26:44.137409Z",
     "start_time": "2025-03-21T17:26:43.690553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CarColorDataset(Dataset):\n",
    "    def __init__(self, image_paths, colors, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.colors = colors\n",
    "        self.transform = transform\n",
    "        \n",
    "        unique_colors = list(set(colors))\n",
    "        self.color_to_idx = {color: idx for idx, color in enumerate(unique_colors)}\n",
    "        self.idx_to_color = {idx: color for idx, color in enumerate(unique_colors)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        color = self.colors[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, self.color_to_idx[color]\n",
    "\n",
    "image_paths = list(image_colors.keys())\n",
    "colors = list(image_colors.values())\n",
    "\n",
    "color_counts = pd.Series(colors).value_counts()\n",
    "print(\"распределение цветов в датасете:\")\n",
    "print(color_counts)\n",
    "\n",
    "min_samples_per_class = 3\n",
    "valid_colors = color_counts[color_counts >= min_samples_per_class].index.tolist()\n",
    "print(f\"\\nцвета с как минимум {min_samples_per_class} образцами: {valid_colors}\")\n",
    "\n",
    "filtered_indices = [i for i, color in enumerate(colors) if color in valid_colors]\n",
    "filtered_image_paths = [image_paths[i] for i in filtered_indices]\n",
    "filtered_colors = [colors[i] for i in filtered_indices]\n",
    "\n",
    "print(f\"размер исходного датасета: {len(colors)} изображений\")\n",
    "print(f\"размер отфильтрованного датасета: {len(filtered_colors)} изображений\")\n",
    "\n",
    "def map_rare_colors(color, min_count=3):\n",
    "    if color_counts[color] < min_count:\n",
    "        return \"other\"\n",
    "    return color\n",
    "\n",
    "grouped_image_paths = image_paths.copy()\n",
    "grouped_colors = [map_rare_colors(color) for color in colors]\n",
    "\n",
    "grouped_color_counts = pd.Series(grouped_colors).value_counts()\n",
    "print(\"\\nраспределение цветов после группировки:\")\n",
    "print(grouped_color_counts)\n",
    "\n",
    "use_filtering = False\n",
    "\n",
    "if use_filtering:\n",
    "    processed_image_paths = filtered_image_paths\n",
    "    processed_colors = filtered_colors\n",
    "else:\n",
    "    processed_image_paths = grouped_image_paths\n",
    "    processed_colors = grouped_colors\n",
    "\n",
    "print(f\"\\nиспользуем {'фильтрацию редких цветов' if use_filtering else 'группировку редких цветов в Other'}\")\n",
    "print(f\"итоговый размер датасета: {len(processed_colors)} изображений\")\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    processed_image_paths, processed_colors, test_size=0.15, random_state=42, stratify=processed_colors\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.15, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"размер обучающей выборки: {len(X_train)}\")\n",
    "print(f\"размер валидационной выборки: {len(X_val)}\")\n",
    "print(f\"размер тестовой выборки: {len(X_test)}\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = CarColorDataset(X_train, y_train, transform=train_transform)\n",
    "val_dataset = CarColorDataset(X_val, y_val, transform=val_test_transform)\n",
    "test_dataset = CarColorDataset(X_test, y_test, transform=val_test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_dataset.color_to_idx)\n",
    "print(f\"всего классов (цветов): {num_classes}\")\n",
    "print(f\"маппинг цветов: {train_dataset.color_to_idx}\")"
   ],
   "id": "8485d86797da79c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "распределение цветов в датасете:\n",
      "Black          14317\n",
      "Grey            9474\n",
      "White           9395\n",
      "Blue            8483\n",
      "Silver          7770\n",
      "Red             6095\n",
      "Unlisted        1516\n",
      "Brown            911\n",
      "Green            777\n",
      "Yellow           667\n",
      "Beige            600\n",
      "Orange           559\n",
      "Purple           362\n",
      "Bronze           329\n",
      "Gold             217\n",
      "Multicolour      196\n",
      "Pink              87\n",
      "Turquoise         26\n",
      "Maroon            26\n",
      "Burgundy           9\n",
      "Magenta            9\n",
      "Navy               1\n",
      "Indigo             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "цвета с как минимум 3 образцами: ['Black', 'Grey', 'White', 'Blue', 'Silver', 'Red', 'Unlisted', 'Brown', 'Green', 'Yellow', 'Beige', 'Orange', 'Purple', 'Bronze', 'Gold', 'Multicolour', 'Pink', 'Turquoise', 'Maroon', 'Burgundy', 'Magenta']\n",
      "размер исходного датасета: 61827 изображений\n",
      "размер отфильтрованного датасета: 61825 изображений\n",
      "\n",
      "распределение цветов после группировки:\n",
      "Black          14317\n",
      "Grey            9474\n",
      "White           9395\n",
      "Blue            8483\n",
      "Silver          7770\n",
      "Red             6095\n",
      "Unlisted        1516\n",
      "Brown            911\n",
      "Green            777\n",
      "Yellow           667\n",
      "Beige            600\n",
      "Orange           559\n",
      "Purple           362\n",
      "Bronze           329\n",
      "Gold             217\n",
      "Multicolour      196\n",
      "Pink              87\n",
      "Turquoise         26\n",
      "Maroon            26\n",
      "Burgundy           9\n",
      "Magenta            9\n",
      "other              2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "используем группировку редких цветов в Other\n",
      "итоговый размер датасета: 61827 изображений\n",
      "размер обучающей выборки: 44669\n",
      "размер валидационной выборки: 7883\n",
      "размер тестовой выборки: 9275\n",
      "всего классов (цветов): 22\n",
      "маппинг цветов: {'Maroon': 0, 'Orange': 1, 'Pink': 2, 'Burgundy': 3, 'Grey': 4, 'Gold': 5, 'Turquoise': 6, 'Unlisted': 7, 'Black': 8, 'Beige': 9, 'Silver': 10, 'White': 11, 'Bronze': 12, 'other': 13, 'Brown': 14, 'Purple': 15, 'Multicolour': 16, 'Red': 17, 'Green': 18, 'Yellow': 19, 'Magenta': 20, 'Blue': 21}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`ValueError: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.`",
   "id": "15091bf1aad23bf0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T17:26:44.148993Z",
     "start_time": "2025-03-21T17:26:44.144931Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6acb7134ac22f24e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T17:26:45.149649Z",
     "start_time": "2025-03-21T17:26:44.269485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_resnet_from_scratch(num_classes):\n",
    "    # ResNet50 случайные веса\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model_from_scratch = create_resnet_from_scratch(num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device.type)\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n",
    "model_from_scratch = model_from_scratch.to(device)\n",
    "\n",
    "# функция потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_from_scratch.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n"
   ],
   "id": "1edf9786dffa6b6b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atheb\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\atheb\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2.6.0+cu126\n",
      "True\n",
      "12.6\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-21T17:26:45.261509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_f1_scores = []\n",
    "    val_f1_scores = []\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    best_model_weights = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for inputs, labels in pbar:\n",
    "            print(inputs.device)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        # валидация\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                print(inputs.device)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        epoch_val_loss = running_loss / len(val_loader.dataset)\n",
    "        epoch_val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        if epoch_val_f1 > best_val_f1:\n",
    "            best_val_f1 = epoch_val_f1\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "        \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        train_f1_scores.append(epoch_train_f1)\n",
    "        val_f1_scores.append(epoch_val_f1)\n",
    "        \n",
    "        print(f'epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'train Loss: {epoch_train_loss:.4f}, train F1: {epoch_train_f1:.4f}')\n",
    "        print(f'val Loss: {epoch_val_loss:.4f}, val F1: {epoch_val_f1:.4f}')\n",
    "        print('-' * 60)\n",
    "    \n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model, train_losses, val_losses, train_f1_scores, val_f1_scores\n",
    "\n",
    "print(\"обучение ResNet50 с нуля...\")\n",
    "model_from_scratch, train_losses_scratch, val_losses_scratch, train_f1_scratch, val_f1_scratch = train_model(\n",
    "    model_from_scratch, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20\n",
    ")"
   ],
   "id": "cb912887d4a21bbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "обучение ResNet50 с нуля...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "epoch 1/20 [Train]:   0%|          | 0/1396 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06b68068d372448ebe9068f30fd348f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
